<div className="animate-in prose">
  <div className="flex flex-col gap-4">
      <div className="text-3xl font-bold leading-tight tracking-tight text-primary">
        Analysis-Paralysis
      </div>
      <div className="text-muted-foreground">
        A comparative analysis of text-to-image models, setting the stage for working on text-to-scene generation.
      </div>

    <div className="flex space-x-2">
      <div className="">
      <img src="/kaveesh.jpg" height={50} width={50} className="rounded-md"/>
      </div>
      <div>
        <p>Kaveesh Khattar</p>
        <p className="text-muted-foreground">Dec 30, 2023</p>
      </div>
    </div>

    <div className="flex flex-col gap-16">

      <div>
        <img src="/banner.png" className="rounded-md w-[calc(100%+48px)] md:rounded-lg" />
      </div>

      <div className="flex flex-col gap-16">

        <div className="flex flex-col gap-4">

        <h2 className="text-xl font-semibold">The Problem Statement</h2>
        <p>To identify the advantages and disadvantages of various text-to-image creation techniques and learn about the underlying mechanisms that contribute to their picture synthesis skills by investigating their architectural designs.</p>
        </div>

        <div className="flex flex-col gap-4">
        <h2 className="text-xl font-semibold">Datasets</h2>

        <p>The datasets used in the comparative analysis paper encompass a diverse range of applications in computer vision and multimedia research.</p>

        <p>YFCC100M, a massive collection of 100 million Flickr images and videos, supports advancements in visual perception, while MS-COCO, with its rich annotations for object detection and segmentation, has fueled cutting-edge research in visual comprehension.</p>

        <p>The CUB dataset focuses on fine-grained bird species recognition, and the Oxford-102 Flowers dataset aids in the fine-grained classification of floral species. Together, these datasets enable significant progress in object detection, classification, and attribute prediction tasks.</p>

        <p>KTH Action Recognition: Evaluates human action recognition, featuring six activities like walking, running, and boxing, with spatio-temporal analysis focus.</p>

        <p>UCF Sports: Highlights sports activity recognition in videos, with diverse action classes like basketball and diving, aiding sports video analysis.</p>
        

        
        
        </div>

        <div className="flex flex-col gap-4">
        <h2 className="text-xl font-semibold">Architectures</h2>

        <p>Our work emphasized deeper experimentation with GAN-based approaches, given their impact on image synthesis.</p>

        <div>Key architectures included **Multi-Stage AttnGAN**, which improves text-to-image synthesis using attention mechanisms; **CycleGAN + BERT**, blending style transfer with text embeddings for nuanced transformations; and **DF-GAN**, which simplifies GAN training for text-to-image tasks. We also examined **MirrorGAN**, which leverages captions for bidirectional consistency, **LSTM+GAN**, integrating sequential modeling for dynamic image generation, and **DALLE**, OpenAI's model for generating high-quality images from text prompts.</div>
        </div>

        <div className="flex flex-col gap-4">
        <h2 className="text-xl font-semibold">Metrics</h2>

        <p>We explored several metrics used to evaluate AI generated images. The **Inception Score (IS)** measures image quality and diversity by comparing class probabilities of generated images. The **Fr√©chet Inception Distance (FID)** quantifies the similarity between real and generated image distributions, with lower FID indicating better quality.</p>

        <p>For subjective evaluation, the **Mean Opinion Score (MOS)** involved human ratings of image fidelity on a numerical scale, with higher scores reflecting greater realism. These metrics collectively ensured a balanced assessment of quality, diversity, and user perception.</p>
        </div>

        <div className="flex flex-col gap-4">
        <h2 className="text-xl font-semibold">The Final Result</h2>
        <p>We submitted our paper to ACI 2023 for publication, and our paper was successfully published!</p>

        <figure className="flex flex-col justify-center items-center space-y-2">
          <img src="/aci.png" className="rounded-md"/>
          <figcaption className="text-center text-muted-foreground">ACI 2023</figcaption>
          </figure>
        </div>
      </div>
    </div>

  </div>
</div>
